{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extract data \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil\n",
    "import torch\n",
    "from PIL import Image\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "os.makedirs('./benign', exist_ok=True)\n",
    "os.makedirs('./malignant', exist_ok=True)\n",
    "def getListOfFiles(dirName):\n",
    "    listOfFile = os.listdir(dirName)\n",
    "    allFiles = []\n",
    "    for entry in listOfFile:\n",
    "        fullPath = os.path.join(dirName, entry)\n",
    "        if os.path.isdir(fullPath):\n",
    "            allFiles.extend(getListOfFiles(fullPath))\n",
    "        else:\n",
    "            allFiles.append(fullPath)\n",
    "    return allFiles\n",
    "files_benign = getListOfFiles('../input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/benign')\n",
    "for f in files_benign:\n",
    "    if f.endswith('.png'):\n",
    "        shutil.copy(f, './benign')\n",
    "files_malignant = getListOfFiles('../input/breakhis/BreaKHis_v1/BreaKHis_v1/histology_slides/breast/malignant')\n",
    "for f in files_malignant:\n",
    "    if f.endswith('.png'):\n",
    "        shutil.copy(f, './malignant')\n",
    "\n",
    "# Get file paths for benign and malignant images and sort them\n",
    "benign_images = sorted(getListOfFiles('./benign'))\n",
    "malignant_images = sorted(getListOfFiles('./malignant'))\n",
    "\n",
    "# Create a DataFrame to store image paths and targets\n",
    "# Assign label 0 for benign and 1 for malignant\n",
    "image_paths = benign_images + malignant_images\n",
    "labels = [0]*len(benign_images) + [1]*len(malignant_images)\n",
    "data = pd.DataFrame({'image': image_paths, 'target': labels})\n",
    "\n",
    "# Output the result\n",
    "print(f\"Total data samples: {data.shape[0]}\")\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "\n",
    "from transformers import (\n",
    "    AutoImageProcessor,\n",
    "    BeitModel,\n",
    "    Swinv2Model,\n",
    "    ConvNextModel,\n",
    "    ViTModel,\n",
    "    CLIPProcessor,\n",
    "    CLIPModel,\n",
    "    AutoModel\n",
    ")\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def extract_magnification(file_path):\n",
    "    filename = os.path.basename(file_path)\n",
    "    parts = filename.split('-')\n",
    "    if len(parts) >= 4:\n",
    "        return parts[3]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "data['magnification'] = data['image'].apply(extract_magnification)\n",
    "\n",
    "if data['magnification'].isnull().any():\n",
    "    print(\"Some magnification values were not extracted. These rows will be removed.\")\n",
    "    data = data.dropna(subset=['magnification'])\n",
    "\n",
    "train_val_data, test_data = train_test_split(\n",
    "    data,\n",
    "    test_size=0.3,\n",
    "    random_state=62,\n",
    "    stratify=data['target']\n",
    ")\n",
    "train_val_data = train_val_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)\n",
    "\n",
    "train_data, val_data = train_test_split(\n",
    "    train_val_data,\n",
    "    test_size=0.1,\n",
    "    random_state=62,\n",
    "    stratify=train_val_data['target']\n",
    ")\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "val_data = val_data.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Augmentation and Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "light_augmentation = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "])\n",
    "\n",
    "augmented_dir = './augmented_images'\n",
    "os.makedirs(augmented_dir, exist_ok=True)\n",
    "\n",
    "print(\"Applying data augmentation and saving augmented images...\")\n",
    "augmented_images = []\n",
    "for idx, row in tqdm(train_data.iterrows(), total=train_data.shape[0]):\n",
    "    image_path = row['image']\n",
    "    target = row['target']\n",
    "    magnification = row['magnification']\n",
    "    try:\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        augmented_image = light_augmentation(image)\n",
    "\n",
    "        base_name = os.path.basename(image_path)\n",
    "        new_name = f\"aug_{idx}_{base_name}\"\n",
    "        new_path = os.path.join(augmented_dir, new_name)\n",
    "\n",
    "        augmented_image.save(new_path)\n",
    "\n",
    "        augmented_images.append({\n",
    "            'image': new_path,\n",
    "            'target': target,\n",
    "            'magnification': magnification\n",
    "        })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing image {image_path}: {e}\")\n",
    "\n",
    "augmented_data = pd.DataFrame(augmented_images)\n",
    "\n",
    "train_data = pd.concat([train_data, augmented_data], ignore_index=True)\n",
    "print(f\"Number of training samples after augmentation: {train_data.shape[0]}\")\n",
    "\n",
    "beit_processor = AutoImageProcessor.from_pretrained('microsoft/beit-large-patch16-224-pt22k-ft22k')\n",
    "beit_model = BeitModel.from_pretrained('microsoft/beit-large-patch16-224-pt22k-ft22k').to(device)\n",
    "\n",
    "swin_processor = AutoImageProcessor.from_pretrained('microsoft/swinv2-large-patch4-window12-192-22k')\n",
    "swin_model = Swinv2Model.from_pretrained('microsoft/swinv2-large-patch4-window12-192-22k').to(device)\n",
    "\n",
    "convnext_processor = AutoImageProcessor.from_pretrained('facebook/convnext-large-224-22k-1k')\n",
    "convnext_model = ConvNextModel.from_pretrained('facebook/convnext-large-224-22k-1k').to(device)\n",
    "\n",
    "vit_processor = AutoImageProcessor.from_pretrained('google/vit-large-patch16-224-in21k')\n",
    "vit_model = ViTModel.from_pretrained('google/vit-large-patch16-224-in21k').to(device)\n",
    "\n",
    "clip_processor = CLIPProcessor.from_pretrained('openai/clip-vit-large-patch14')\n",
    "clip_model = CLIPModel.from_pretrained('openai/clip-vit-large-patch14').to(device)\n",
    "\n",
    "phikon_processor = AutoImageProcessor.from_pretrained(\"owkin/phikon\")\n",
    "phikon_model = AutoModel.from_pretrained(\"owkin/phikon\").to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features and filter data based on magnification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features_batch(image_paths):\n",
    "    images = []\n",
    "    valid_indices = []\n",
    "    for idx, path in enumerate(image_paths):\n",
    "        try:\n",
    "            image = Image.open(path).convert('RGB')\n",
    "            images.append(image)\n",
    "            valid_indices.append(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {path}: {e}\")\n",
    "    if not images:\n",
    "        return np.array([]), []\n",
    "\n",
    "    beit_inputs = beit_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "    swin_inputs = swin_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "    convnext_inputs = convnext_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "    vit_inputs = vit_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "    clip_inputs = clip_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "    phikon_inputs = phikon_processor(images=images, return_tensors=\"pt\", padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        beit_outputs = beit_model(**beit_inputs)\n",
    "        swin_outputs = swin_model(**swin_inputs)\n",
    "        convnext_outputs = convnext_model(**convnext_inputs)\n",
    "        vit_outputs = vit_model(**vit_inputs)\n",
    "        clip_outputs = clip_model.get_image_features(**clip_inputs)\n",
    "        phikon_outputs = phikon_model(**phikon_inputs)\n",
    "\n",
    "    beit_features = beit_outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    swin_features = swin_outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    convnext_features = convnext_outputs.last_hidden_state.mean(dim=[2, 3]).cpu().numpy()\n",
    "    vit_features = vit_outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "    clip_features = clip_outputs.cpu().numpy()\n",
    "    phikon_features = phikon_outputs.last_hidden_state.mean(dim=1).cpu().numpy()\n",
    "\n",
    "    features = np.concatenate(\n",
    "        [beit_features, convnext_features, swin_features, vit_features, clip_features, phikon_features],\n",
    "        axis=1\n",
    "    )\n",
    "    return features, valid_indices\n",
    "\n",
    "def process_in_batches(image_paths, batch_size=32):\n",
    "    all_features = []\n",
    "    all_indices = []\n",
    "    num_batches = len(image_paths) // batch_size + int(len(image_paths) % batch_size != 0)\n",
    "\n",
    "    for i in tqdm(range(num_batches), desc=\"Processing batches\"):\n",
    "        batch_paths = image_paths[i * batch_size: (i + 1) * batch_size]\n",
    "        batch_features, valid_indices = extract_features_batch(batch_paths)\n",
    "        if batch_features.size > 0:\n",
    "            all_features.append(batch_features)\n",
    "            batch_indices = [i * batch_size + idx for idx in valid_indices]\n",
    "            all_indices.extend(batch_indices)\n",
    "    if all_features:\n",
    "        all_features = np.concatenate(all_features, axis=0)\n",
    "    else:\n",
    "        all_features = np.array([])\n",
    "    return all_features, all_indices\n",
    "\n",
    "print(\"Extracting features for training set...\")\n",
    "X_train, train_indices = process_in_batches(\n",
    "    train_data['image'].tolist(),\n",
    "    batch_size=120\n",
    ")\n",
    "print(\"Extracting features for validation set...\")\n",
    "X_val, val_indices = process_in_batches(\n",
    "    val_data['image'].tolist(),\n",
    "    batch_size=120\n",
    ")\n",
    "print(\"Extracting features for test set...\")\n",
    "X_test, test_indices = process_in_batches(\n",
    "    test_data['image'].tolist(),\n",
    "    batch_size=120\n",
    ")\n",
    "\n",
    "train_data = train_data.iloc[train_indices].reset_index(drop=True)\n",
    "val_data = val_data.iloc[val_indices].reset_index(drop=True)\n",
    "test_data = test_data.iloc[test_indices].reset_index(drop=True)\n",
    "\n",
    "y_train = train_data['target'].values\n",
    "y_val = val_data['target'].values\n",
    "y_test = test_data['target'].values\n",
    "\n",
    "assert X_train.shape[0] == y_train.shape[0], \"Mismatch between training features and labels\"\n",
    "assert X_val.shape[0] == y_val.shape[0], \"Mismatch between validation features and labels\"\n",
    "assert X_test.shape[0] == y_test.shape[0], \"Mismatch between test features and labels\"\n",
    "\n",
    "def filter_all_magnifications(train_data, val_data, test_data, X_train, y_train, X_val, y_val, X_test, y_test, magnifications):\n",
    "    filtered_data = {}\n",
    "    for mag in magnifications:\n",
    "        train_mask = train_data['magnification'] == mag\n",
    "        val_mask = val_data['magnification'] == mag\n",
    "        test_mask = test_data['magnification'] == mag\n",
    "\n",
    "        X_train_filtered = X_train[train_mask.values]\n",
    "        y_train_filtered = y_train[train_mask.values]\n",
    "        X_val_filtered = X_val[val_mask.values]\n",
    "        y_val_filtered = y_val[val_mask.values]\n",
    "        X_test_filtered = X_test[test_mask.values]\n",
    "        y_test_filtered = y_test[test_mask.values]\n",
    "\n",
    "        filtered_data[mag] = {\n",
    "            'X_train': X_train_filtered,\n",
    "            'y_train': y_train_filtered,\n",
    "            'X_val': X_val_filtered,\n",
    "            'y_val': y_val_filtered,\n",
    "            'X_test': X_test_filtered,\n",
    "            'y_test': y_test_filtered\n",
    "        }\n",
    "    return filtered_data\n",
    "\n",
    "magnifications = ['40', '100', '200', '400']\n",
    "\n",
    "filtered_data = filter_all_magnifications(\n",
    "    train_data, val_data, test_data, X_train, y_train, X_val, y_val, X_test, y_test, magnifications\n",
    ")\n",
    "\n",
    "X_train_40 = filtered_data['40']['X_train']\n",
    "y_train_40 = filtered_data['40']['y_train']\n",
    "X_val_40 = filtered_data['40']['X_val']\n",
    "y_val_40 = filtered_data['40']['y_val']\n",
    "X_test_40 = filtered_data['40']['X_test']\n",
    "y_test_40 = filtered_data['40']['y_test']\n",
    "\n",
    "X_train_100 = filtered_data['100']['X_train']\n",
    "y_train_100 = filtered_data['100']['y_train']\n",
    "X_val_100 = filtered_data['100']['X_val']\n",
    "y_val_100 = filtered_data['100']['y_val']\n",
    "X_test_100 = filtered_data['100']['X_test']\n",
    "y_test_100 = filtered_data['100']['y_test']\n",
    "\n",
    "X_train_200 = filtered_data['200']['X_train']\n",
    "y_train_200 = filtered_data['200']['y_train']\n",
    "X_val_200 = filtered_data['200']['X_val']\n",
    "y_val_200 = filtered_data['200']['y_val']\n",
    "X_test_200 = filtered_data['200']['X_test']\n",
    "y_test_200 = filtered_data['200']['y_test']\n",
    "\n",
    "X_train_400 = filtered_data['400']['X_train']\n",
    "y_train_400 = filtered_data['400']['y_train']\n",
    "X_val_400 = filtered_data['400']['X_val']\n",
    "y_val_400 = filtered_data['400']['y_val']\n",
    "X_test_400 = filtered_data['400']['X_test']\n",
    "y_test_400 = filtered_data['400']['y_test']\n",
    "\n",
    "print(f\"Number of X_train_40: {len(X_train_40)}\")\n",
    "print(f\"Number of y_train_40: {len(y_train_40)}\")\n",
    "print(f\"Number of X_val_40: {len(X_val_40)}\")\n",
    "print(f\"Number of y_val_40: {len(y_val_40)}\")\n",
    "print(f\"Number of X_test_40: {len(X_test_40)}\")\n",
    "print(f\"Number of y_test_40: {len(y_test_40)}\\n\")\n",
    "\n",
    "print(f\"Number of X_train_100: {len(X_train_100)}\")\n",
    "print(f\"Number of y_train_100: {len(y_train_100)}\")\n",
    "print(f\"Number of X_val_100: {len(X_val_100)}\")\n",
    "print(f\"Number of y_val_100: {len(y_val_100)}\")\n",
    "print(f\"Number of X_test_100: {len(X_test_100)}\")\n",
    "print(f\"Number of y_test_100: {len(y_test_100)}\\n\")\n",
    "\n",
    "print(f\"Number of X_train_200: {len(X_train_200)}\")\n",
    "print(f\"Number of y_train_200: {len(y_train_200)}\")\n",
    "print(f\"Number of X_val_200: {len(X_val_200)}\")\n",
    "print(f\"Number of y_val_200: {len(y_val_200)}\")\n",
    "print(f\"Number of X_test_200: {len(X_test_200)}\")\n",
    "print(f\"Number of y_test_200: {len(y_test_200)}\\n\")\n",
    "\n",
    "print(f\"Number of X_train_400: {len(X_train_400)}\")\n",
    "print(f\"Number of y_train_400: {len(y_train_400)}\")\n",
    "print(f\"Number of X_val_400: {len(X_val_400)}\")\n",
    "print(f\"Number of y_val_400: {len(y_val_400)}\")\n",
    "print(f\"Number of X_test_400: {len(X_test_400)}\")\n",
    "print(f\"Number of y_test_400: {len(y_test_400)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Models for Different Magnifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 16\n",
    "saves = []\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "\n",
    "def train_model(X_train, y_train, X_val, y_val, X_test, y_test, mag, save_prefix):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_val_scaled = scaler.transform(X_val)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    y_train = np.array(y_train).astype('float32')\n",
    "    y_val = np.array(y_val).astype('float32')\n",
    "    y_test = np.array(y_test).astype('float32')\n",
    "    \n",
    "    model = Sequential([\n",
    "        Dense(2048, input_dim=X_train_scaled.shape[1], activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(1024, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        \n",
    "        Dense(512, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "        Dense(256, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.5),\n",
    "\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    initial_lr = 0.001\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=initial_lr)\n",
    "    model.compile(optimizer=optimizer,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    checkpoint = ModelCheckpoint(f'best_model_{mag}.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=4, min_lr=1e-9, verbose=1)\n",
    "    \n",
    "    history = model.fit(\n",
    "        X_train_scaled, y_train,\n",
    "        epochs=50,\n",
    "        batch_size=batch,\n",
    "        validation_data=(X_val_scaled, y_val),\n",
    "        callbacks=[checkpoint, lr_scheduler],\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred = np.round(y_pred).astype(int).flatten()\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f'Test Accuracy for magnification {mag}: {test_accuracy}')\n",
    "    \n",
    "    save_path = f'{save_prefix}_{batch}_{mag}_accuracy_{test_accuracy}.keras'\n",
    "    saves.append(save_path)\n",
    "    model.save(save_path)\n",
    "    return test_accuracy\n",
    "\n",
    "def train_models_for_all_magnifications(\n",
    "    X_train_40, y_train_40, X_val_40, y_val_40, X_test_40, y_test_40,\n",
    "    X_train_100, y_train_100, X_val_100, y_val_100, X_test_100, y_test_100,\n",
    "    X_train_200, y_train_200, X_val_200, y_val_200, X_test_200, y_test_200,\n",
    "    X_train_400, y_train_400, X_val_400, y_val_400, X_test_400, y_test_400):\n",
    "    \n",
    "    accuracies = {}\n",
    "    accuracies['40'] = train_model(\n",
    "        X_train_40, y_train_40, X_val_40, y_val_40, X_test_40, y_test_40, '40', 'model_40'\n",
    "    )\n",
    "    accuracies['100'] = train_model(\n",
    "        X_train_100, y_train_100, X_val_100, y_val_100, X_test_100, y_test_100, '100', 'model_100'\n",
    "    )\n",
    "    accuracies['200'] = train_model(\n",
    "        X_train_200, y_train_200, X_val_200, y_val_200, X_test_200, y_test_200, '200', 'model_200'\n",
    "    )\n",
    "    accuracies['400'] = train_model(\n",
    "        X_train_400, y_train_400, X_val_400, y_val_400, X_test_400, y_test_400, '400', 'model_400'\n",
    "    )\n",
    "    return accuracies\n",
    "\n",
    "accuracies = train_models_for_all_magnifications(\n",
    "    X_train_40, y_train_40, X_val_40, y_val_40, X_test_40, y_test_40,\n",
    "    X_train_100, y_train_100, X_val_100, y_val_100, X_test_100, y_test_100,\n",
    "    X_train_200, y_train_200, X_val_200, y_val_200, X_test_200, y_test_200,\n",
    "    X_train_400, y_train_400, X_val_400, y_val_400, X_test_400, y_test_400\n",
    ")\n",
    "\n",
    "print(\"Accuracies for each magnification level:\")\n",
    "for mag, acc in accuracies.items():\n",
    "    print(f\"{mag}x magnification: {acc}\")\n",
    "\n",
    "num_samples = {\n",
    "    '40': len(X_test_40),\n",
    "    '100': len(X_test_100),\n",
    "    '200': len(X_test_200),\n",
    "    '400': len(X_test_400)\n",
    "}\n",
    "\n",
    "total_samples = sum(num_samples.values())\n",
    "\n",
    "weighted_accuracy = sum((num_samples[mag] / total_samples) * acc for mag, acc in accuracies.items())\n",
    "\n",
    "print(f\"Weighted accuracy across all magnifications: {weighted_accuracy}\")\n",
    "\n",
    "\n",
    "def zip_saved_models(file_paths, zip_filename):\n",
    "    with zipfile.ZipFile(zip_filename, 'w') as zipf:\n",
    "        for file_path in file_paths:\n",
    "            if os.path.isfile(file_path): \n",
    "                zipf.write(file_path, os.path.basename(file_path))\n",
    "            else:\n",
    "                print(f\"File not found: {file_path}\")\n",
    "    \n",
    "    print(f\"Selected files have been zipped into {zip_filename}\")\n",
    "\n",
    "output_zip_filename = f'{weighted_accuracy}.zip'\n",
    "\n",
    "zip_saved_models(saves, output_zip_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Use the Phikon model for 100x magnification and the combined model for 40x, 200x, and 400x magnifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import FileLink, display\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "X_test_100_ph = np.load('/kaggle/input/ph-data/X_test_100_ph.npy')\n",
    "y_test_100_ph = np.load('/kaggle/input/ph-data/y_test_100_ph.npy')\n",
    "def recreate_and_save_scaler(X_train, mag):\n",
    "    \"\"\"\n",
    "    Recreate the StandardScaler using training data and save it.\n",
    "    \n",
    "    Args:\n",
    "        X_train (numpy.ndarray): Training features.\n",
    "        mag (str): Magnification level identifier.\n",
    "    \"\"\"\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)\n",
    "    scaler_filename = f'scaler_{mag}_all.pkl'\n",
    "    joblib.dump(scaler, scaler_filename)\n",
    "    print(f'Scaler for {mag}x magnification saved as {scaler_filename}')\n",
    "\n",
    "recreate_and_save_scaler(X_train_40, '40')\n",
    "recreate_and_save_scaler(X_test_100_ph, '100')\n",
    "recreate_and_save_scaler(X_train_200, '200')\n",
    "recreate_and_save_scaler(X_train_400, '400')\n",
    "\n",
    "def load_scaler(scaler_filename):\n",
    "    if os.path.exists(scaler_filename):\n",
    "        scaler = joblib.load(scaler_filename)\n",
    "        print(f'Scaler loaded from {scaler_filename}')\n",
    "        return scaler\n",
    "    else:\n",
    "        print(f'Scaler file {scaler_filename} not found.')\n",
    "        return None\n",
    "\n",
    "def load_and_predict(model_path, scaler, X_test, y_test, mag):\n",
    "    model = load_model(model_path)\n",
    "    print(f'Model loaded from {model_path}')\n",
    "    \n",
    "    if scaler is not None:\n",
    "        X_test_scaled = scaler.transform(X_test)\n",
    "    else:\n",
    "        print('Scaler is None. Proceeding without scaling.')\n",
    "        X_test_scaled = X_test  \n",
    "    \n",
    "    y_pred_prob = model.predict(X_test_scaled)\n",
    "    y_pred = np.round(y_pred_prob).astype(int).flatten()\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'Test Accuracy for {mag}x Magnification: {acc:.4f}')\n",
    "    \n",
    "    print(f'Classification Report for {mag}x Magnification:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(f'Confusion Matrix for {mag}x Magnification:')\n",
    "    print(cm)\n",
    "    \n",
    "    return acc, cm\n",
    "\n",
    "def plot_confusion_matrices(confusion_matrices, magnifications, figsize=(20, 5), save_path=None):\n",
    "    num_mags = len(magnifications)\n",
    "    fig, axes = plt.subplots(1, num_mags, figsize=figsize)\n",
    "    \n",
    "    if num_mags == 1:\n",
    "        axes = [axes]  \n",
    "    \n",
    "    for ax, mag in zip(axes, magnifications):\n",
    "        cm = confusion_matrices[mag]\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, ax=ax)\n",
    "        ax.set_title(f'Confusion Matrix: {mag}x')\n",
    "        ax.set_xlabel('Predicted Labels')\n",
    "        ax.set_ylabel('True Labels')\n",
    "        ax.xaxis.set_ticklabels(['Negative (0)', 'Positive (1)'])\n",
    "        ax.yaxis.set_ticklabels(['Negative (0)', 'Positive (1)'])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    if save_path:\n",
    "        plt.savefig(save_path)\n",
    "        print(f'Confusion matrices saved to {save_path}')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def create_download_link(filepath, title=\"Download Image\"):\n",
    "    if os.path.exists(filepath):\n",
    "        display(FileLink(filepath, result_html_prefix=f'<p>{title}: '))\n",
    "    else:\n",
    "        print(f\"File {filepath} not found.\")\n",
    "\n",
    "model_info = {\n",
    "    '40': {\n",
    "        'model_path': \"/kaggle/input/model-99.1-not-ph/pytorch/default/1/model_40_16_40_accuracy_0.9919743178170144.keras\",\n",
    "        'scaler_path': '/kaggle/input/scaler-ph-and-other/scaler_40_all.pkl',\n",
    "        'X_test': X_test_40,\n",
    "        'y_test': y_test_40\n",
    "    },\n",
    "    '100': {\n",
    "        'model_path':\"/kaggle/input/ph-100-93/pytorch/default/1/model_100_16_100_accuracy_0.9932318104906938.keras\" ,\n",
    "        'scaler_path': '/kaggle/input/scaler-ph-and-other/scaler_100.pkl',\n",
    "        'X_test': X_test_100_ph,\n",
    "        'y_test': y_test_100_ph\n",
    "    },\n",
    "    '200': {\n",
    "        'model_path': '/kaggle/input/model-99.1-not-ph/pytorch/default/1/model_200_16_200_accuracy_0.9982758620689656.keras',\n",
    "        'scaler_path': '/kaggle/input/scaler-ph-and-other/scaler_200_all.pkl',\n",
    "        'X_test': X_test_200,\n",
    "        'y_test': y_test_200\n",
    "    },\n",
    "    '400': {\n",
    "        'model_path': '/kaggle/input/model-99.1-not-ph/pytorch/default/1/model_400_16_400_accuracy_0.9913644214162349.keras',\n",
    "        'scaler_path': '/kaggle/input/scaler-ph-and-other/scaler_400_all.pkl',\n",
    "        'X_test': X_test_400,\n",
    "        'y_test': y_test_400\n",
    "    }\n",
    "}\n",
    "\n",
    "test_accuracies = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "for mag, info in model_info.items():\n",
    "    model_path = info['model_path']\n",
    "    scaler_path = info['scaler_path']\n",
    "    X_test = info['X_test']\n",
    "    y_test = info['y_test']\n",
    "    \n",
    "    print(f\"\\nProcessing {mag}x Magnification:\")\n",
    "    \n",
    "    scaler = load_scaler(scaler_path)\n",
    "    \n",
    "    acc, cm = load_and_predict(model_path, scaler, X_test, y_test, mag)\n",
    "    \n",
    "    test_accuracies[mag] = acc\n",
    "    confusion_matrices[mag] = cm\n",
    "\n",
    "print(\"\\nTest Accuracies for Each Magnification Level:\")\n",
    "for mag, acc in test_accuracies.items():\n",
    "    print(f\"{mag}x Magnification: {acc:.4f}\")\n",
    "\n",
    "magnifications = ['40', '100', '200', '400']\n",
    "\n",
    "plot_confusion_matrices(confusion_matrices, magnifications, save_path='confusion_matrices.png')\n",
    "\n",
    "create_download_link('confusion_matrices.png', title=\"Click here to download the Confusion Matrices Image\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 209316,
     "sourceId": 999617,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5758026,
     "sourceId": 9469039,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5796811,
     "sourceId": 9520927,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 118195,
     "modelInstanceId": 93983,
     "sourceId": 112119,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 118217,
     "modelInstanceId": 94005,
     "sourceId": 112143,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 118223,
     "modelInstanceId": 94011,
     "sourceId": 112153,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 118310,
     "modelInstanceId": 94097,
     "sourceId": 112250,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 118312,
     "modelInstanceId": 94099,
     "sourceId": 112252,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 118313,
     "modelInstanceId": 94100,
     "sourceId": 112253,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 118314,
     "modelInstanceId": 94101,
     "sourceId": 112254,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 118315,
     "modelInstanceId": 94102,
     "sourceId": 112255,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 118316,
     "modelInstanceId": 94103,
     "sourceId": 112256,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 124453,
     "modelInstanceId": 100285,
     "sourceId": 119256,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
